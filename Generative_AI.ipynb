{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEFkY9OGCVtZOiRSJRf1qG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0dcf89ab381475da0dbcc0cae61d116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2a7161334084066a30355e125437389",
              "IPY_MODEL_7f61d155e381443b9dc96cf1e70aaccd",
              "IPY_MODEL_17bbd5df37dc4983a312affa2c699ca7"
            ],
            "layout": "IPY_MODEL_a981b85fe91d4bc1b8b6eba91cfb0ec2"
          }
        },
        "e2a7161334084066a30355e125437389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e19d68627149f8bda61b93ffde973f",
            "placeholder": "​",
            "style": "IPY_MODEL_f601cda50ebd463eab0989a9f3b4035a",
            "value": "Generating train split: "
          }
        },
        "7f61d155e381443b9dc96cf1e70aaccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843d991030114318a5606e862652bd7f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe912200f00b4492a45b502410902be6",
            "value": 1
          }
        },
        "17bbd5df37dc4983a312affa2c699ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f114e2be824648816ccb9c5faa847b",
            "placeholder": "​",
            "style": "IPY_MODEL_81343657fdc64b43828b9d691e04c67f",
            "value": " 371/0 [00:00&lt;00:00, 4259.11 examples/s]"
          }
        },
        "a981b85fe91d4bc1b8b6eba91cfb0ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14e19d68627149f8bda61b93ffde973f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f601cda50ebd463eab0989a9f3b4035a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843d991030114318a5606e862652bd7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fe912200f00b4492a45b502410902be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78f114e2be824648816ccb9c5faa847b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81343657fdc64b43828b9d691e04c67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c42e464523e8405c8bf28b9d509a3eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70b39f8728ba4866b96cff8b816a222e",
              "IPY_MODEL_41cc8e14d628403d96538de41e768477",
              "IPY_MODEL_527e33c7515a46c48dbb048ab831d3bc"
            ],
            "layout": "IPY_MODEL_12efcc7ce6f14d0588711e3c946572a2"
          }
        },
        "70b39f8728ba4866b96cff8b816a222e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7347025511643c6aa5d6fa898191747",
            "placeholder": "​",
            "style": "IPY_MODEL_da2af6aba11d419fab8bfb12bb9ec81e",
            "value": "Map: 100%"
          }
        },
        "41cc8e14d628403d96538de41e768477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4ecd825224d41dc94acabd171134490",
            "max": 371,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11ea6fb974bb45acab140aa64dc86b7a",
            "value": 371
          }
        },
        "527e33c7515a46c48dbb048ab831d3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068568c3c71f4c0b905b256a4158cc79",
            "placeholder": "​",
            "style": "IPY_MODEL_3847dbe742704b76bb96453f197335b1",
            "value": " 371/371 [00:00&lt;00:00, 566.66 examples/s]"
          }
        },
        "12efcc7ce6f14d0588711e3c946572a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7347025511643c6aa5d6fa898191747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2af6aba11d419fab8bfb12bb9ec81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4ecd825224d41dc94acabd171134490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11ea6fb974bb45acab140aa64dc86b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "068568c3c71f4c0b905b256a4158cc79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3847dbe742704b76bb96453f197335b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84c4a39e8e334ad0bac027fc9e6ef412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1de9a9b1e1c4034a872e13b9568fc0e",
              "IPY_MODEL_b4f15123f25d44a9a839b78fba86dcad",
              "IPY_MODEL_31f88f0d098e4f68a66c5364b4334141"
            ],
            "layout": "IPY_MODEL_64db3f4c7e8445ba9f597fe753849325"
          }
        },
        "e1de9a9b1e1c4034a872e13b9568fc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f87139b3cb846bba9c200afa959b83d",
            "placeholder": "​",
            "style": "IPY_MODEL_64134fd5ecba432f84d423f4acc245ae",
            "value": "Downloading builder script: "
          }
        },
        "b4f15123f25d44a9a839b78fba86dcad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57ee0deda2994af99a23ade44b9dbf58",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40331528bdcb43dcbbcc7137d8d2d57f",
            "value": 1
          }
        },
        "31f88f0d098e4f68a66c5364b4334141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6825e54e6d384a68bead767694f34630",
            "placeholder": "​",
            "style": "IPY_MODEL_af8227fed9d8499883007195f10a6f0d",
            "value": " 4.20k/? [00:00&lt;00:00, 202kB/s]"
          }
        },
        "64db3f4c7e8445ba9f597fe753849325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f87139b3cb846bba9c200afa959b83d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64134fd5ecba432f84d423f4acc245ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57ee0deda2994af99a23ade44b9dbf58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "40331528bdcb43dcbbcc7137d8d2d57f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6825e54e6d384a68bead767694f34630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af8227fed9d8499883007195f10a6f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshini-R-SpireNSavvy/P1/blob/main/Generative_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CJ671_1YycL",
        "outputId": "5e09c9bf-86dd-4c7e-cc2b-aba9680e88e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'datasets'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Total 78 (delta 0), reused 0 (delta 0), pack-reused 78 (from 1)\u001b[K\n",
            "Receiving objects: 100% (78/78), 41.86 MiB | 13.72 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n",
            "Updating files: 100% (29/29), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nlpfromscratch/datasets.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate evaluate bitsandbytes peft huggingface_hub --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwAUrnjXY4MZ",
        "outputId": "efd3d6de-bfa0-468f-b426-5da844170e77"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate\n",
            "  Using cached evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2025.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests (from transformers)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting psutil (from accelerate)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting torch>=2.0.0 (from accelerate)\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub)\n",
            "  Downloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
            "  Downloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting setuptools (from torch>=2.0.0->accelerate)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=2.0.0->accelerate)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=2.0.0->accelerate)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch>=2.0.0->accelerate)\n",
            "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->accelerate)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->accelerate)\n",
            "  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.9/504.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m811.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.6/355.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytz, nvidia-cusparselt-cu12, mpmath, xxhash, urllib3, tzdata, typing-extensions, tqdm, sympy, six, setuptools, safetensors, regex, pyyaml, pyarrow, psutil, propcache, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, MarkupSafe, idna, hf-xet, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, triton, requests, python-dateutil, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, jinja2, aiosignal, pandas, nvidia-cusolver-cu12, huggingface_hub, aiohttp, torch, tokenizers, transformers, datasets, bitsandbytes, accelerate, peft, evaluate\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.5.0\n",
            "    Uninstalling xxhash-3.5.0:\n",
            "      Successfully uninstalled xxhash-3.5.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.2\n",
            "    Uninstalling safetensors-0.6.2:\n",
            "      Successfully uninstalled safetensors-0.6.2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.3.2\n",
            "    Uninstalling propcache-0.3.2:\n",
            "      Successfully uninstalled propcache-0.3.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.6.4\n",
            "    Uninstalling multidict-6.6.4:\n",
            "      Successfully uninstalled multidict-6.6.4\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.9\n",
            "    Uninstalling hf-xet-1.1.9:\n",
            "      Successfully uninstalled hf-xet-1.1.9\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.7.0\n",
            "    Uninstalling frozenlist-1.7.0:\n",
            "      Successfully uninstalled frozenlist-1.7.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.19.1\n",
            "    Uninstalling filelock-3.19.1:\n",
            "      Successfully uninstalled filelock-3.19.1\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.20.1\n",
            "    Uninstalling yarl-1.20.1:\n",
            "      Successfully uninstalled yarl-1.20.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "rARLOJpEdwRQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "id": "9TaWShXReLZr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_pipline = pipeline(\"text-generation\", model=\"gpt2\", device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvuSvukvfbRD",
        "outputId": "6719f22e-cb2d-478f-86f0-7a07e436b6ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = gpt2_pipline(\"I love applesauce\" , num_return_sequences=5)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJDrVLKzeXqj",
        "outputId": "a7f7c8ce-c36d-4f3f-bb36-ff879b9a6630"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'I love applesauce, and it tastes great. One of my favorite things about this recipe is how much moisture it adds, and how much it takes to get it from the ground up. As you can see, there are some things I don\\'t like about it, but for me it is just a nice little treat that I find myself making for a few occasions.\\n\\nI can\\'t tell you how many times I\\'ve made this recipe with a fork and my kids just stare at it. I know they would say \"What is that?!\" and I\\'ll always say, \"It\\'s just a little sweet. It\\'s just like applesauce. Just a little sweet. Sweet.\" I\\'m sure they will feel the same way.\\n\\nIt\\'s a good idea to add some of the dry ingredients and add a little to your recipe. You can also add some sugar or other sweetener if you want to. The dry ingredients are just like applesauce, but better.\\n\\nI\\'ve also found that I don\\'t like the taste of sugar as much as my other recipes. I like the feeling of the applesauce. There is just something good about these applesauce. You can\\'t go wrong with one of my other recipe. Just put the seeds on top'}, {'generated_text': 'I love applesauce. The more I try to think about it, the more I think it\\'s delicious. It\\'s a nice thing to be able to eat and I think it\\'s something I can enjoy.\"\\n\\n\"One of the things is that I don\\'t have to worry about it too much anymore,\" she added. \"I enjoy the whole apple pie. I love having an apple pie with me.\"\\n\\nAfter lunch at a restaurant in Boston, she decided to try something new. She made her own apple pie with a homemade cinnamon sugar apple pie filling and whipped cream, a cinnamon sugar apple pie filling and a cinnamon sugar apple pie filling.\\n\\n\"I\\'m a big fan of cinnamon sugar, so I\\'m not really sure how I would go about doing it,\" she said. \"We just picked up a few apples that we used, and I think that\\'s what they\\'re making it, because they\\'re basically cinnamon sugar. I think that\\'s what people are talking about as well.\"\\n\\nHer cinnamon sugar apple pie recipe is below.\\n\\nCinnamon sugar apple pie filling\\n\\n4 cups all-purpose flour\\n\\n8 tablespoons pumpkin puree\\n\\n4 tablespoons coconut oil\\n\\n1/4 teaspoon cinnamon\\n\\n3/4 teaspoon vanilla extract\\n\\n'}, {'generated_text': 'I love applesauce, if you can call it that. It makes me happy.\\n\\nNow I\\'m going to go with the new version. This time, I\\'ve added a little bit more to the mix. I\\'m going to make a little bit more of a \"doodle\" with it. Because that\\'s a good idea.\\n\\nFirst things first, I\\'m going to add a few things to the sauce. I mean, this is a sauce that doesn\\'t have a lot of salt. You know, you can make it with a little bit of olive or a little bit of sugar, but I just want to get it right. I want it to be a little bit more salty, and that\\'s what I\\'m going to be adding to it. That\\'s going to be a little bit of salt. I\\'m going to be adding a bit more, a little bit more.\\n\\nAnd I\\'m going to add a little bit more of sugar. If you just like to add a little bit of sugar, you can add it to the sauce, but you can add a little bit more. But you can\\'t add too much.\\n\\nI\\'m going to add some sugar. I\\'m going to add some lemon juice. I\\'m going to add some honey'}, {'generated_text': 'I love applesauce. But I just can\\'t get into the culture of it. I don\\'t love it. We don\\'t love it. And I\\'m not going to go out and get my applesauce. I\\'m just going to try it.\"\\n\\nThe team at the time, who were playing with some friends (who are now teammates, not a team) and were already playing with their new teammates, called a meeting.\\n\\n\"We just got together and said, \\'We\\'re going to do this,\\'\" said Tom Stauffer, who played in the 2005-06 Chicago Bulls and has played with them since. \"There was an announcement about Chicago coming to the NBA and we were all like, \\'Well, we\\'re going to do this.\\' But we were like, \\'No, we\\'re not going to start playing with the Bulls.\\'\"\\n\\nThey decided to play with the Bulls.\\n\\n\"We had a lot of other conversations about it and we felt like doing this was the right thing to do,\" said Stauffer. \"We thought it would be a great thing, and this is the right thing to do. Because we thought it would be a good thing to do. And of course, it was. It took a little bit of time'}, {'generated_text': 'I love applesauce and I love being open about my love for apple pie. I love the taste of the apple pie. I really love the smell of the sweet apple pie. I love the taste of the hot apple pie. I love the taste of the maple syrup. I love the smell of the cinnamon. I love the aroma of the lemon. I love the smell of the vanilla. I love the smell of the chocolate. I love the smell of the pine trees. I love the smell of the apricots. I love the smell of the vanilla. I love the aroma of the chocolates. I love the smell of the vanilla. I love the smell of the chocolate. I love the smell of the vanilla. I love the smell of the hazelnuts. I love the smell of the apricots. I love the smell of the chocolate. I love the smell of the lemon. I love the smell of the dark chocolate. I love the smell of the pumpkin pie. I love the smell of the sweet vanilla. I love the smell of the apple pie. I love the smell of the maple syrup. I love the smell of the cinnamon. I love the smell of the sweet vanilla. I love the smell of the cherries. I love the smell of'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(gpt2_pipline.tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "zZSvI-sLhi4K",
        "outputId": "22069ecb-375a-4496-93a2-cda386ec156e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast</b><br/>def __call__(text: Union[TextInput, PreTokenizedInput, list[TextInput], list[PreTokenizedInput], None]=None, text_pair: Optional[Union[TextInput, PreTokenizedInput, list[TextInput], list[PreTokenizedInput]]]=None, text_target: Union[TextInput, PreTokenizedInput, list[TextInput], list[PreTokenizedInput], None]=None, text_pair_target: Optional[Union[TextInput, PreTokenizedInput, list[TextInput], list[PreTokenizedInput]]]=None, add_special_tokens: bool=True, padding: Union[bool, str, PaddingStrategy]=False, truncation: Union[bool, str, TruncationStrategy, None]=None, max_length: Optional[int]=None, stride: int=0, is_split_into_words: bool=False, pad_to_multiple_of: Optional[int]=None, padding_side: Optional[str]=None, return_tensors: Optional[Union[str, TensorType]]=None, return_token_type_ids: Optional[bool]=None, return_attention_mask: Optional[bool]=None, return_overflowing_tokens: bool=False, return_special_tokens_mask: bool=False, return_offsets_mapping: bool=False, return_length: bool=False, verbose: bool=True, **kwargs) -&gt; BatchEncoding</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/tokenization_gpt2_fast.py</a>Construct a &quot;fast&quot; GPT-2 tokenizer (backed by HuggingFace&#x27;s *tokenizers* library). Based on byte-level\n",
              "Byte-Pair-Encoding.\n",
              "\n",
              "This tokenizer has been trained to treat spaces like parts of the tokens (a bit like sentencepiece) so a word will\n",
              "be encoded differently whether it is at the beginning of the sentence (without space) or not:\n",
              "\n",
              "```python\n",
              "&gt;&gt;&gt; from transformers import GPT2TokenizerFast\n",
              "\n",
              "&gt;&gt;&gt; tokenizer = GPT2TokenizerFast.from_pretrained(&quot;openai-community/gpt2&quot;)\n",
              "&gt;&gt;&gt; tokenizer(&quot;Hello world&quot;)[&quot;input_ids&quot;]\n",
              "[15496, 995]\n",
              "\n",
              "&gt;&gt;&gt; tokenizer(&quot; Hello world&quot;)[&quot;input_ids&quot;]\n",
              "[18435, 995]\n",
              "```\n",
              "\n",
              "You can get around that behavior by passing `add_prefix_space=True` when instantiating this tokenizer, but since\n",
              "the model was not pretrained this way, it might yield a decrease in performance.\n",
              "\n",
              "&lt;Tip&gt;\n",
              "\n",
              "When used with `is_split_into_words=True`, this tokenizer needs to be instantiated with `add_prefix_space=True`.\n",
              "\n",
              "&lt;/Tip&gt;\n",
              "\n",
              "This tokenizer inherits from [`PreTrainedTokenizerFast`] which contains most of the main methods. Users should\n",
              "refer to this superclass for more information regarding those methods.\n",
              "\n",
              "Args:\n",
              "    vocab_file (`str`, *optional*):\n",
              "        Path to the vocabulary file.\n",
              "    merges_file (`str`, *optional*):\n",
              "        Path to the merges file.\n",
              "    tokenizer_file (`str`, *optional*):\n",
              "        Path to [tokenizers](https://github.com/huggingface/tokenizers) file (generally has a .json extension) that\n",
              "        contains everything needed to load the tokenizer.\n",
              "    unk_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):\n",
              "        The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n",
              "        token instead.\n",
              "    bos_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):\n",
              "        The beginning of sequence token.\n",
              "    eos_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):\n",
              "        The end of sequence token.\n",
              "    add_prefix_space (`bool`, *optional*, defaults to `False`):\n",
              "        Whether or not to add an initial space to the input. This allows to treat the leading word just as any\n",
              "        other word. (GPT2 tokenizer detect beginning of words by the preceding space).</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 30);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(gpt2_pipline.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "gpG6NcHOhwTT",
        "outputId": "e5338054-2283-4973-a13d-0e39ef954297"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py</a>The GPT2 Model transformer with a language modeling head on top (linear layer with weights tied to the input\n",
              "embeddings).\n",
              "\n",
              "This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
              "library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
              "etc.)\n",
              "\n",
              "This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.\n",
              "Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\n",
              "and behavior.\n",
              "\n",
              "Parameters:\n",
              "    config ([`GPT2LMHeadModel`]):\n",
              "        Model configuration class with all the parameters of the model. Initializing with a config file does not\n",
              "        load the weights associated with the model, only the configuration. Check out the\n",
              "        [`~PreTrainedModel.from_pretrained`] method to load the model weights.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 977);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f\"{gpt2_pipline.model.num_parameters():,}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yiMk2mB2h4UG",
        "outputId": "7c30fefe-bf2f-4e47-bc57-0a924395f73f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'124,439,808'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_input_string = \"The rain in Spain falls mainly in the plain\"\n",
        "\n",
        "output = gpt2_pipline(my_input_string)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGYOuXKZjYEr",
        "outputId": "1b99557d-8d83-4bfd-fedd-ffa031911565"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"The rain in Spain falls mainly in the plain of the San Sebastian, which is home to the world's largest lake and the world's largest tropical rain forest.\\n\\nThe city of Granada, which is home to more than 30 million people, is a major tourism draw.\\n\\nThe city of Barcelona is home to a number of historic sites and is one of the most visited tourist destinations in Spain.\\n\\nThe city is home to the world's largest lake and the world's largest tropical rain forest\\n\\nThe rain falls mostly in the plain of the San Sebastian, which is home to the world's largest lake and the world's largest tropical rain forest\\n\\nThere was an estimated 800,000 people in Granada last year, a number that grew to more than 80,000 in 2016, according to the government statistics.\\n\\nThe city's population is estimated to be about a third of the total Spanish population, with about three quarters of the capital's population living in the city.\\n\\nThe city has a population of about 4.6 million.\\n\\nThe rain leaves the city almost completely dry, making it a little bit more difficult to find food.\\n\\nThere is also a problem with the sea, which has been blamed for the city's dryness.\\n\\nThe rain is falling\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n"
      ],
      "metadata": {
        "id": "vFyOimKcmUeD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(device)\n",
        "my_input_string = \"The rain in Spain falls mainly in the plain\""
      ],
      "metadata": {
        "id": "yvG8GMXJkQI4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = tokenizer(my_input_string, return_tensors=\"pt\").to(device)\n"
      ],
      "metadata": {
        "id": "Cs_b0S9ulbHv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8c7ZqKVlrUj",
        "outputId": "575f2988-964e-4a99-9bea-c46032842d33"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 464, 6290,  287, 8602, 8953, 8384,  287,  262, 8631]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(**model_inputs)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFB3OuKrl3CO",
        "outputId": "892852b5-7766-42ce-e095-b6c4f5d84d0d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  464,  6290,   287,  8602,  8953,  8384,   287,   262,  8631,   286,\n",
            "           262, 50206, 12010,    11,   475,   340,   318,   635,   287,   262,\n",
            "         12269,   286,   262, 50206, 12010,    13,   383,  6290,   318]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the tokens back to text using the tokenizer\n",
        "output_string = tokenizer.decode(output[0])\n",
        "\n",
        "# Print the result\n",
        "display(Markdown(\"---\"))  # dividing line\n",
        "display(Markdown(output_string))\n",
        "display(Markdown(\"---\"))  # dividing line\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "l6--zK1-moPf",
        "outputId": "e900a8ac-b513-46a7-9bcf-d65655ddfc3e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain of the Canary Islands, but it is also in the mountains of the Canary Islands. The rain is"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_output = model.generate(**model_inputs)\n",
        "\n",
        "print(greedy_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ufirlLyo9Sz",
        "outputId": "b08c4394-1031-4c7e-db0a-bea7c27b87a5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  464,  6290,   287,  8602,  8953,  8384,   287,   262,  8631,   286,\n",
            "           262, 50206, 12010,    11,   475,   340,   318,   635,   287,   262,\n",
            "         12269,   286,   262, 50206, 12010,    13,   383,  6290,   318]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "greedy_output = model.generate(**model_inputs)\n",
        "output_string = tokenizer.decode(greedy_output[0])\n",
        "\n",
        "print(output_string)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__A47RBppZUk",
        "outputId": "ddf58206-d4f6-49f9-a70d-d0c5776d7311"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The rain in Spain falls mainly in the plain of the Canary Islands, but it is also in the mountains of the Canary Islands. The rain is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "greedy_output2 = model.generate(**model_inputs)\n",
        "output_string2 = tokenizer.decode(greedy_output2[0])\n",
        "\n",
        "print(output_string2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEz4sRsBpcg6",
        "outputId": "f9d84237-edc9-4825-d5ce-d42b31c3bc40"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The rain in Spain falls mainly in the plain of the Canary Islands, but it is also in the mountains of the Canary Islands. The rain is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_string = \"The rain in Spain falls mainly in the plain\"\n",
        "\n",
        "model_inputs = tokenizer(input_string, return_tensors='pt').to(device)\n",
        "\n",
        "greedy_output = model.generate(**model_inputs, num_beams=10, early_stopping=True)\n",
        "\n",
        "output_string = tokenizer.decode(greedy_output[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVx-fg27pi9d",
        "outputId": "52127026-f51e-4588-e232-22315aee17c3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(output_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Ba9wJPFypz29",
        "outputId": "eccaa2c3-434a-4aab-f03d-dffbe4c7da7a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain to the south of the city of Barcelona.\n\nThe city is also home to some of the"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text input string\n",
        "input_string = \"The rain in Spain falls mainly in the plain\"\n",
        "\n",
        "# Generation = temperature ~= 0 → deterministic\n",
        "model_inputs = tokenizer(input_string, return_tensors='pt').to(device)\n",
        "zero_temp_output = model.generate(**model_inputs, temperature=1, do_sample=True)\n",
        "\n",
        "# Iterate over outputs and display in markdown\n",
        "display(Markdown(\"---\"))\n",
        "for output in zero_temp_output:\n",
        "    output_string = tokenizer.decode(output)\n",
        "    display(Markdown(output_string))\n",
        "display(Markdown(\"---\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "k_HBerpKqG5l",
        "outputId": "bc16fdcc-1f50-4570-85cc-5edeaa228254"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain of Catalonia, a major part of Spain's industrial heartland.\n\nCatalonia's official statistics"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text input string\n",
        "input_string = \"The rain in Spain falls mainly in the plain\"\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Define device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(device)\n",
        "model_inputs = tokenizer(input_string, return_tensors='pt').to(device)\n",
        "\n",
        "# Generation - Top-k & Top-p\n",
        "top_k_output = model.generate(**model_inputs, top_k=30, do_sample=True, num_return_sequences=5)\n",
        "top_p_output = model.generate(**model_inputs, top_p=0.5, do_sample=True, num_return_sequences=5)\n",
        "\n",
        "# Top K\n",
        "display(Markdown(\"---\"))\n",
        "display(Markdown(\"Top-k, $k=30$:\"))\n",
        "for output in top_k_output:\n",
        "    output_string = tokenizer.decode(output)\n",
        "    display(Markdown(output_string))\n",
        "\n",
        "# Top P\n",
        "display(Markdown(\"---\"))\n",
        "display(Markdown(\"Top-p, $p=0.5$:\"))\n",
        "for output in top_p_output:\n",
        "    output_string = tokenizer.decode(output)\n",
        "    display(Markdown(output_string))\n",
        "display(Markdown(\"---\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "JJ3b3zv033IW",
        "outputId": "3f739d4f-18e1-4b9f-c73f-5433d485da26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Top-k, $k=30$:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain of Barcelona and is the longest on record, as well as a sign the Spanish coast is still hot"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain of La Monde de Ville, from which it traverses over many areas.\n\n\""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain of the city of Sainte-Nouven, the capital of Sint-Anton"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain but in the mountains it falls through fields and can be seen across the country.\n\nSpain has"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain, and it spreads further into the central and northern parts. The snow from Spain falls in the same"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Top-p, $p=0.5$:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain of the Canary Islands, and is particularly heavy in the north of the island.\n\nThe rain"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain of the Andalusia Mountains.\n\nThe most common method of precipitation is the rain that falls"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain of the Canary Islands, and it is only in the summer that it is able to provide the necessary"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain, which is covered by a layer of thick vegetation, and the ground is covered with thick, flat"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The rain in Spain falls mainly in the plain of Valencia, where it has been known to rain in the winter. The rain is so bad that"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "---"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from IPython.display import Markdown\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = \"cude\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "k67C3BIO4JMV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset/yoda/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py-dzbCS7Xza",
        "outputId": "a441f8d9-de34-4253-faf4-1eadf21de867"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'dataset/yoda/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "yoda_df = pd.read_csv(\"/content/yoda-corpus.csv\")\n",
        "\n",
        "yoda_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kUJfvkeW8DAe",
        "outputId": "b4b8fa01-fe86-4f64-f70f-cd866fff7a6d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movie  scene  line   character  \\\n",
              "0      1    129  1158    narrator   \n",
              "1      1    129  1159     QUI-GON   \n",
              "2      1    129  1160  MACE WINDU   \n",
              "3      1    129  1161      KI-ADI   \n",
              "4      1    129  1162        YODA   \n",
              "\n",
              "                                                text  \\\n",
              "0  QUI-GON stands in a tall stately room. Twelve ...   \n",
              "1  ...my only conclusion can be that it was a Sit...   \n",
              "2                                     A Sith Lord?!?   \n",
              "3  Impossible! The Sith have been extinct for a m...   \n",
              "4  The very Republic is threatened, if involved t...   \n",
              "\n",
              "                                               slug  component  \n",
              "0  INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY     action  \n",
              "1  INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY  character  \n",
              "2  INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY  character  \n",
              "3  INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY  character  \n",
              "4  INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY  character  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2beddd6-c392-4177-9371-6d3158456fb5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie</th>\n",
              "      <th>scene</th>\n",
              "      <th>line</th>\n",
              "      <th>character</th>\n",
              "      <th>text</th>\n",
              "      <th>slug</th>\n",
              "      <th>component</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>129</td>\n",
              "      <td>1158</td>\n",
              "      <td>narrator</td>\n",
              "      <td>QUI-GON stands in a tall stately room. Twelve ...</td>\n",
              "      <td>INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY</td>\n",
              "      <td>action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>129</td>\n",
              "      <td>1159</td>\n",
              "      <td>QUI-GON</td>\n",
              "      <td>...my only conclusion can be that it was a Sit...</td>\n",
              "      <td>INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY</td>\n",
              "      <td>character</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>129</td>\n",
              "      <td>1160</td>\n",
              "      <td>MACE WINDU</td>\n",
              "      <td>A Sith Lord?!?</td>\n",
              "      <td>INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY</td>\n",
              "      <td>character</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>129</td>\n",
              "      <td>1161</td>\n",
              "      <td>KI-ADI</td>\n",
              "      <td>Impossible! The Sith have been extinct for a m...</td>\n",
              "      <td>INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY</td>\n",
              "      <td>character</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>129</td>\n",
              "      <td>1162</td>\n",
              "      <td>YODA</td>\n",
              "      <td>The very Republic is threatened, if involved t...</td>\n",
              "      <td>INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY</td>\n",
              "      <td>character</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2beddd6-c392-4177-9371-6d3158456fb5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2beddd6-c392-4177-9371-6d3158456fb5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2beddd6-c392-4177-9371-6d3158456fb5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-10d405b1-0bc2-491e-9b9b-aa14ecf37897\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10d405b1-0bc2-491e-9b9b-aa14ecf37897')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-10d405b1-0bc2-491e-9b9b-aa14ecf37897 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "yoda_df",
              "summary": "{\n  \"name\": \"yoda_df\",\n  \"rows\": 371,\n  \"fields\": [\n    {\n      \"column\": \"movie\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          3,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scene\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 48,\n        \"max\": 234,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          90,\n          178,\n          129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 418,\n        \"min\": 341,\n        \"max\": 1705,\n        \"num_unique_values\": 334,\n        \"samples\": [\n          1183,\n          353,\n          1328\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"character\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"YODA\\t (shakes his head)\",\n          \"CLONE SERGEANT\",\n          \"MACE WlNDU\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 367,\n        \"samples\": [\n          \" It's nothing, nothing. All these Wookiees are dead. Move to the east.\",\n          \"No, sir.\",\n          \"A vergence, you say?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slug\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"91 INT. KASHYYYK-HOLOGRAM AREA-DAY\",\n          \"226 INT. POLIS MASSA-MEDICAL CENTER-NIGHT\",\n          \"90 INT. KASHYYYK-HOLOGRAM AREA-DAY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"component\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"character\",\n          \"action\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data_files = [\"/content/yoda-corpus.csv\"]\n",
        "\n",
        "dataset = load_dataset(\"csv\", data_files=data_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c0dcf89ab381475da0dbcc0cae61d116",
            "e2a7161334084066a30355e125437389",
            "7f61d155e381443b9dc96cf1e70aaccd",
            "17bbd5df37dc4983a312affa2c699ca7",
            "a981b85fe91d4bc1b8b6eba91cfb0ec2",
            "14e19d68627149f8bda61b93ffde973f",
            "f601cda50ebd463eab0989a9f3b4035a",
            "843d991030114318a5606e862652bd7f",
            "fe912200f00b4492a45b502410902be6",
            "78f114e2be824648816ccb9c5faa847b",
            "81343657fdc64b43828b9d691e04c67f"
          ]
        },
        "id": "LJ1wElYoKjzV",
        "outputId": "2599e958-6b63-4e55-ff91-e794cc6c71b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0dcf89ab381475da0dbcc0cae61d116"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxaNkAFDLIei",
        "outputId": "f95cb437-3aef-4ccf-9973-d21548c2d31f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['movie', 'scene', 'line', 'character', 'text', 'slug', 'component'],\n",
              "        num_rows: 371\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnpL3kpoLKkF",
        "outputId": "2e9d1e5c-ec08-425b-c59c-e074242226d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "# Use GPU\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Instantiate model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(device)\n"
      ],
      "metadata": {
        "id": "14fX0w8FLujJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate inputs for model\n",
        "input = tokenizer(\"The rain in Spain\", return_tensors=\"pt\").to(device)\n",
        "print(input)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv_VAHi-L7Mf",
        "outputId": "7a4ca403-489b-49a3-900e-9764071320ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 464, 6290,  287, 8602]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate model outputs\n",
        "output = model.generate(**input, max_new_tokens=20)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IdiiY1PL-NN",
        "outputId": "bd64a4d8-ed4e-4c33-ab8a-231c13fe1a1f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  464,  6290,   287,  8602,   468,   587,   523,  2089,   326,   262,\n",
            "          1748,   286, 15142,   468,   587,  4137,   284,  1969,   663,  8215,\n",
            "            13,   198,   198,   464]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFDqEK-lMHhm",
        "outputId": "cb29d6a5-eafb-425b-bc0f-da1fa0474e8b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The rain in Spain has been so bad that the city of Barcelona has been forced to close its doors.\n",
            "\n",
            "The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWroXKFvMTBy",
        "outputId": "0a9bd1a1-b724-4a6c-85f9-4e303cf29596"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'movie': [1, 1, 1, 1, 1],\n",
              " 'scene': [129, 129, 129, 129, 129],\n",
              " 'line': [1158, 1159, 1160, 1161, 1162],\n",
              " 'character': ['narrator', 'QUI-GON', 'MACE WINDU', 'KI-ADI', 'YODA'],\n",
              " 'text': ['QUI-GON stands in a tall stately room. Twelve JEDI sit in a semi-circle. OBI-WAN stands behind QUI-GON in the center of the room. The Senior Jedi is MACE WINDU. To his left is an alien Jedi named KI-ADI-MUNDI, and to his right, the Jedi Master, YODA.',\n",
              "  '...my only conclusion can be that it was a Sith Lord.',\n",
              "  'A Sith Lord?!?',\n",
              "  'Impossible! The Sith have been extinct for a millenium.',\n",
              "  'The very Republic is threatened, if involved the Sith are.'],\n",
              " 'slug': ['INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY',\n",
              "  'INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY',\n",
              "  'INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY',\n",
              "  'INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY',\n",
              "  'INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY'],\n",
              " 'component': ['action', 'character', 'character', 'character', 'character']}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_function(data):\n",
        "    my_tokenizer = tokenizer(data[\"text\"], padding=\"max_length\", truncation=True)\n",
        "    return my_tokenizer\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c42e464523e8405c8bf28b9d509a3eab",
            "70b39f8728ba4866b96cff8b816a222e",
            "41cc8e14d628403d96538de41e768477",
            "527e33c7515a46c48dbb048ab831d3bc",
            "12efcc7ce6f14d0588711e3c946572a2",
            "c7347025511643c6aa5d6fa898191747",
            "da2af6aba11d419fab8bfb12bb9ec81e",
            "e4ecd825224d41dc94acabd171134490",
            "11ea6fb974bb45acab140aa64dc86b7a",
            "068568c3c71f4c0b905b256a4158cc79",
            "3847dbe742704b76bb96453f197335b1"
          ]
        },
        "id": "XfQ2ec9IMxYs",
        "outputId": "ee7ff318-dc2a-4804-cc5c-a721b26cf6d7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/371 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c42e464523e8405c8bf28b9d509a3eab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,5):\n",
        "  print(tokenized_dataset['train'][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV4GpzcxM2A0",
        "outputId": "69d083e7-54fa-4fc6-f966-05acef17a2fd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'movie': 1, 'scene': 129, 'line': 1158, 'character': 'narrator', 'text': 'QUI-GON stands in a tall stately room. Twelve JEDI sit in a semi-circle. OBI-WAN stands behind QUI-GON in the center of the room. The Senior Jedi is MACE WINDU. To his left is an alien Jedi named KI-ADI-MUNDI, and to his right, the Jedi Master, YODA.', 'slug': 'INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY', 'component': 'action', 'input_ids': [43702, 12, 38, 1340, 6296, 287, 257, 7331, 1181, 306, 2119, 13, 30775, 449, 1961, 40, 1650, 287, 257, 10663, 12, 45597, 13, 440, 3483, 12, 54, 1565, 6296, 2157, 1195, 10080, 12, 38, 1340, 287, 262, 3641, 286, 262, 2119, 13, 383, 14017, 16147, 318, 337, 11598, 370, 12115, 52, 13, 1675, 465, 1364, 318, 281, 8756, 16147, 3706, 509, 40, 12, 2885, 40, 12, 44, 4944, 17931, 11, 290, 284, 465, 826, 11, 262, 16147, 5599, 11, 575, 3727, 32, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'movie': 1, 'scene': 129, 'line': 1159, 'character': 'QUI-GON', 'text': '...my only conclusion can be that it was a Sith Lord.', 'slug': 'INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY', 'component': 'character', 'input_ids': [986, 1820, 691, 7664, 460, 307, 326, 340, 373, 257, 26455, 4453, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'movie': 1, 'scene': 129, 'line': 1160, 'character': 'MACE WINDU', 'text': 'A Sith Lord?!?', 'slug': 'INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY', 'component': 'character', 'input_ids': [32, 26455, 4453, 12248, 30, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'movie': 1, 'scene': 129, 'line': 1161, 'character': 'KI-ADI', 'text': 'Impossible! The Sith have been extinct for a millenium.', 'slug': 'INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY', 'component': 'character', 'input_ids': [26950, 4733, 0, 383, 26455, 423, 587, 28881, 329, 257, 3939, 47477, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'movie': 1, 'scene': 129, 'line': 1162, 'character': 'YODA', 'text': 'The very Republic is threatened, if involved the Sith are.', 'slug': 'INT. TEMPLE OF THE JEDI - COUNCIL CHAMBERS - DAY', 'component': 'character', 'input_ids': [464, 845, 2066, 318, 8556, 11, 611, 2950, 262, 26455, 389, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6y-0TXTOin2",
        "outputId": "e213c764-2840-4524-a016-a58bd3cc7387"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import evaluate\n",
        "\n",
        "# Set up the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"yoda-gpt2\",\n",
        "    num_train_epochs=10,\n",
        "    remove_unused_columns=True,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Set up the metric used to evaluate the training\n",
        "metric = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "0zg6g72dRFmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "91608vTxPcwN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "id": "IsS7g13VPnfN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "texts = dataset['train'][0:4]['text']\n",
        "print(\"Text:\")\n",
        "print(texts)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Tokenize\n",
        "print(\"Tokenized text:\")\n",
        "tokens = [tokenizer(t) for t in texts]\n",
        "print(tokens)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Collate\n",
        "print(\"Collated data\")\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset=tokens, collate_fn=data_collator)\n",
        "\n",
        "for batch in dataloader:\n",
        "    print(batch)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxBg-kcyPznr",
        "outputId": "239d97a3-130c-43eb-8fbe-85ecf477f93c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "['QUI-GON stands in a tall stately room. Twelve JEDI sit in a semi-circle. OBI-WAN stands behind QUI-GON in the center of the room. The Senior Jedi is MACE WINDU. To his left is an alien Jedi named KI-ADI-MUNDI, and to his right, the Jedi Master, YODA.', '...my only conclusion can be that it was a Sith Lord.', 'A Sith Lord?!?', 'Impossible! The Sith have been extinct for a millenium.']\n",
            "\n",
            "\n",
            "Tokenized text:\n",
            "[{'input_ids': [43702, 12, 38, 1340, 6296, 287, 257, 7331, 1181, 306, 2119, 13, 30775, 449, 1961, 40, 1650, 287, 257, 10663, 12, 45597, 13, 440, 3483, 12, 54, 1565, 6296, 2157, 1195, 10080, 12, 38, 1340, 287, 262, 3641, 286, 262, 2119, 13, 383, 14017, 16147, 318, 337, 11598, 370, 12115, 52, 13, 1675, 465, 1364, 318, 281, 8756, 16147, 3706, 509, 40, 12, 2885, 40, 12, 44, 4944, 17931, 11, 290, 284, 465, 826, 11, 262, 16147, 5599, 11, 575, 3727, 32, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [986, 1820, 691, 7664, 460, 307, 326, 340, 373, 257, 26455, 4453, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'input_ids': [32, 26455, 4453, 12248, 30], 'attention_mask': [1, 1, 1, 1, 1]}, {'input_ids': [26950, 4733, 0, 383, 26455, 423, 587, 28881, 329, 257, 3939, 47477, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}]\n",
            "\n",
            "\n",
            "Collated data\n",
            "{'input_ids': tensor([[43702,    12,    38,  1340,  6296,   287,   257,  7331,  1181,   306,\n",
            "          2119,    13, 30775,   449,  1961,    40,  1650,   287,   257, 10663,\n",
            "            12, 45597,    13,   440,  3483,    12,    54,  1565,  6296,  2157,\n",
            "          1195, 10080,    12,    38,  1340,   287,   262,  3641,   286,   262,\n",
            "          2119,    13,   383, 14017, 16147,   318,   337, 11598,   370, 12115,\n",
            "            52,    13,  1675,   465,  1364,   318,   281,  8756, 16147,  3706,\n",
            "           509,    40,    12,  2885,    40,    12,    44,  4944, 17931,    11,\n",
            "           290,   284,   465,   826,    11,   262, 16147,  5599,    11,   575,\n",
            "          3727,    32,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[43702,    12,    38,  1340,  6296,   287,   257,  7331,  1181,   306,\n",
            "          2119,    13, 30775,   449,  1961,    40,  1650,   287,   257, 10663,\n",
            "            12, 45597,    13,   440,  3483,    12,    54,  1565,  6296,  2157,\n",
            "          1195, 10080,    12,    38,  1340,   287,   262,  3641,   286,   262,\n",
            "          2119,    13,   383, 14017, 16147,   318,   337, 11598,   370, 12115,\n",
            "            52,    13,  1675,   465,  1364,   318,   281,  8756, 16147,  3706,\n",
            "           509,    40,    12,  2885,    40,    12,    44,  4944, 17931,    11,\n",
            "           290,   284,   465,   826,    11,   262, 16147,  5599,    11,   575,\n",
            "          3727,    32,    13]])}\n",
            "{'input_ids': tensor([[  986,  1820,   691,  7664,   460,   307,   326,   340,   373,   257,\n",
            "         26455,  4453,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  986,  1820,   691,  7664,   460,   307,   326,   340,   373,   257,\n",
            "         26455,  4453,    13]])}\n",
            "{'input_ids': tensor([[   32, 26455,  4453, 12248,    30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]]), 'labels': tensor([[   32, 26455,  4453, 12248,    30]])}\n",
            "{'input_ids': tensor([[26950,  4733,     0,   383, 26455,   423,   587, 28881,   329,   257,\n",
            "          3939, 47477,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[26950,  4733,     0,   383, 26455,   423,   587, 28881,   329,   257,\n",
            "          3939, 47477,    13]])}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3aA_2LaSYCE",
        "outputId": "f294a00a-51dd-4da6-e361-b7523e7ab592"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.3.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.3.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   ! pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkEbxM1HS1KC",
        "outputId": "43da48c2-436d-484b-b668-fc850e9fa93e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.3.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import evaluate\n",
        "\n",
        "# Set up the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"yoda-gpt2\",\n",
        "    num_train_epochs=10,\n",
        "    remove_unused_columns=True,\n",
        "    # evaluation_strategy=\"epoch\" # Removed the problematic argument\n",
        ")\n",
        "\n",
        "# Set up the metric used to evaluate the training\n",
        "metric = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "84c4a39e8e334ad0bac027fc9e6ef412",
            "e1de9a9b1e1c4034a872e13b9568fc0e",
            "b4f15123f25d44a9a839b78fba86dcad",
            "31f88f0d098e4f68a66c5364b4334141",
            "64db3f4c7e8445ba9f597fe753849325",
            "5f87139b3cb846bba9c200afa959b83d",
            "64134fd5ecba432f84d423f4acc245ae",
            "57ee0deda2994af99a23ade44b9dbf58",
            "40331528bdcb43dcbbcc7137d8d2d57f",
            "6825e54e6d384a68bead767694f34630",
            "af8227fed9d8499883007195f10a6f0d"
          ]
        },
        "id": "FTvSlGsbSShb",
        "outputId": "619f3617-1455-4330-e596-e7c9418cf6bc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84c4a39e8e334ad0bac027fc9e6ef412"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"train\"],\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "USQYFXA5TVQ-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    report_to=\"none\",\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"train\"],\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "id": "LKp5YJ0OUdKH"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we7qgKCBUetT",
        "outputId": "e5e1910f-0d67-4651-8ac4-75e276891a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjEbaWqJWXBJ",
        "outputId": "717d22a0-6739-4ac3-8774-9ee1fc1a4511"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.56.1\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft, sentence-transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Make a dataframe of the log history\n",
        "metrics_df = pd.DataFrame(trainer.state.log_history)\n",
        "\n",
        "# Plot\n",
        "metrics_df['eval_loss'].plot(marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss for GPT-2 Yoda model')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "AIv8VYLpVnlR",
        "outputId": "3ba92c3c-7c8a-4755-9e85-3ca0c2faf93e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2217684288.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Make a dataframe of the log history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmetrics_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import Trainer, TrainingArguments # Assuming Hugging Face Transformers\n",
        "\n",
        "# --- Placeholder for trainer setup ---\n",
        "# In a real scenario, you would define your model, dataset, and training arguments\n",
        "# For demonstration, we'll create a dummy 'trainer' object with a mock log_history\n",
        "\n",
        "class MockTrainerState:\n",
        "    def __init__(self):\n",
        "        self.log_history = [\n",
        "            {'epoch': 1.0, 'eval_loss': 0.5, 'step': 100},\n",
        "            {'epoch': 2.0, 'eval_loss': 0.4, 'step': 200},\n",
        "            {'epoch': 3.0, 'eval_loss': 0.3, 'step': 300},\n",
        "        ]\n",
        "\n",
        "class MockTrainer:\n",
        "    def __init__(self):\n",
        "        self.state = MockTrainerState()\n",
        "\n",
        "trainer = MockTrainer()\n",
        "# --- End of placeholder ---\n",
        "\n",
        "# Make a dataframe of the log history\n",
        "metrics_df = pd.DataFrame(trainer.state.log_history)\n",
        "\n",
        "# Plot\n",
        "metrics_df['eval_loss'].plot(marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss for GPT-2 Yoda model')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "GrLBbPCRWu2p",
        "outputId": "065fc64f-71e4-4aea-e86e-7c5800332592"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls yoda-gpt2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgfLN2SlXVCo",
        "outputId": "25bfe252-682e-4550-c5bb-9446a7b776ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "runs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h yoda-gpt2/model.safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxJPLVcqX0s5",
        "outputId": "d9023efa-e683-4b85-e179-6705e556932a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "du: cannot access 'yoda-gpt2/model.safetensors': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "fc3bc9a6",
        "outputId": "dd21dd71-f174-4628-f01e-31f6b52c2aab"
      },
      "source": [
        "!pip install bitsandbytes"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.47.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    }
  ]
}